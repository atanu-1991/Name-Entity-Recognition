{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"2b5a92096c9047bb80e6194c2f53314d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_22e1ce10beef43b9a4a00bdbff7f4e97","IPY_MODEL_cdcb1f50b5ca4fbba9ceace045f95ce2","IPY_MODEL_0321db72097946e192e48c5c7c42fb4b"],"layout":"IPY_MODEL_a9a988fdeb614c9f8a1f2efead4ec81d"}},"22e1ce10beef43b9a4a00bdbff7f4e97":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a47b308db3df4ab19283732136401495","placeholder":"​","style":"IPY_MODEL_76a7611748414f009b22e01ec3a2f2f0","value":"Downloading builder script: "}},"cdcb1f50b5ca4fbba9ceace045f95ce2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_03beaac1b7e5423da1ddd1d231a707b0","max":2472,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c854188f46e242f0a2cf06ff04cd5793","value":2472}},"0321db72097946e192e48c5c7c42fb4b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_53d7b36db74144f687e51966e57cf97d","placeholder":"​","style":"IPY_MODEL_fae165e1aa034aaf9189139af5bd62de","value":" 6.33k/? [00:00&lt;00:00, 383kB/s]"}},"a9a988fdeb614c9f8a1f2efead4ec81d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a47b308db3df4ab19283732136401495":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"76a7611748414f009b22e01ec3a2f2f0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"03beaac1b7e5423da1ddd1d231a707b0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c854188f46e242f0a2cf06ff04cd5793":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"53d7b36db74144f687e51966e57cf97d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fae165e1aa034aaf9189139af5bd62de":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"_RXUsZUEJKFO","executionInfo":{"status":"ok","timestamp":1693313765069,"user_tz":-330,"elapsed":3364,"user":{"displayName":"Atanu Kundu","userId":"00561738222071394876"}}},"outputs":[],"source":["# Install\n","!pip install transformers datasets tokenizers seqeval -q"]},{"cell_type":"code","source":["!pip install --upgrade accelerate\n","!pip uninstall -y transformers accelerate\n","!pip install transformers accelerate"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RrKo6sadQ1Zx","executionInfo":{"status":"ok","timestamp":1693313789952,"user_tz":-330,"elapsed":19489,"user":{"displayName":"Atanu Kundu","userId":"00561738222071394876"}},"outputId":"42408117-d5e0-4d5f-ab20-06d9698ae9ab"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.22.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.1)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n","Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.0.1+cu118)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.12.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.7.1)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.10.0->accelerate) (3.27.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.10.0->accelerate) (16.0.6)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n","Found existing installation: transformers 4.32.1\n","Uninstalling transformers-4.32.1:\n","  Successfully uninstalled transformers-4.32.1\n","Found existing installation: accelerate 0.22.0\n","Uninstalling accelerate-0.22.0:\n","  Successfully uninstalled accelerate-0.22.0\n","Collecting transformers\n","  Using cached transformers-4.32.1-py3-none-any.whl (7.5 MB)\n","Collecting accelerate\n","  Using cached accelerate-0.22.0-py3-none-any.whl (251 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.16.4)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.3.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n","Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.0.1+cu118)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.7.1)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.10.0->accelerate) (3.27.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.10.0->accelerate) (16.0.6)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.2.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n","Installing collected packages: transformers, accelerate\n","Successfully installed accelerate-0.22.0 transformers-4.32.1\n"]}]},{"cell_type":"code","source":["import datasets\n","import numpy as np\n","from transformers import BertTokenizerFast\n","from transformers import DataCollatorForTokenClassification\n","from transformers import AutoModelForTokenClassification"],"metadata":{"id":"uPEusft8KuC4","executionInfo":{"status":"ok","timestamp":1693313799631,"user_tz":-330,"elapsed":6575,"user":{"displayName":"Atanu Kundu","userId":"00561738222071394876"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["conll2003 = datasets.load_dataset(\"conll2003\")"],"metadata":{"id":"fpVXIhe_LfjM","executionInfo":{"status":"ok","timestamp":1693313804863,"user_tz":-330,"elapsed":2023,"user":{"displayName":"Atanu Kundu","userId":"00561738222071394876"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["conll2003"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SwcgrkMXLfh2","executionInfo":{"status":"ok","timestamp":1693313808871,"user_tz":-330,"elapsed":15,"user":{"displayName":"Atanu Kundu","userId":"00561738222071394876"}},"outputId":"e0432c91-70d3-412f-c4bd-07bb64d34120"},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n","        num_rows: 14041\n","    })\n","    validation: Dataset({\n","        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n","        num_rows: 3250\n","    })\n","    test: Dataset({\n","        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n","        num_rows: 3453\n","    })\n","})"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["conll2003[\"train\"][0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jpI3gz9XLfeY","executionInfo":{"status":"ok","timestamp":1693313811509,"user_tz":-330,"elapsed":11,"user":{"displayName":"Atanu Kundu","userId":"00561738222071394876"}},"outputId":"7b92aa75-61c5-4c7f-f109-b17c39213e1e"},"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'id': '0',\n"," 'tokens': ['EU',\n","  'rejects',\n","  'German',\n","  'call',\n","  'to',\n","  'boycott',\n","  'British',\n","  'lamb',\n","  '.'],\n"," 'pos_tags': [22, 42, 16, 21, 35, 37, 16, 21, 7],\n"," 'chunk_tags': [11, 21, 11, 12, 21, 22, 11, 12, 0],\n"," 'ner_tags': [3, 0, 7, 0, 0, 0, 7, 0, 0]}"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["conll2003[\"train\"].features[\"ner_tags\"]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VLc5g0_kLfb4","executionInfo":{"status":"ok","timestamp":1693313813879,"user_tz":-330,"elapsed":10,"user":{"displayName":"Atanu Kundu","userId":"00561738222071394876"}},"outputId":"377d24d2-8bb0-49af-b54c-368940367b07"},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Sequence(feature=ClassLabel(names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC'], id=None), length=-1, id=None)"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["conll2003['train'].description"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":174},"id":"7vzqWBXmL6TZ","executionInfo":{"status":"ok","timestamp":1693313818013,"user_tz":-330,"elapsed":33,"user":{"displayName":"Atanu Kundu","userId":"00561738222071394876"}},"outputId":"51785179-8197-4823-e6fc-bc07881fa7e5"},"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'The shared task of CoNLL-2003 concerns language-independent named entity recognition. We will concentrate on\\nfour types of named entities: persons, locations, organizations and names of miscellaneous entities that do\\nnot belong to the previous three groups.\\n\\nThe CoNLL-2003 shared task data files contain four columns separated by a single space. Each word has been put on\\na separate line and there is an empty line after each sentence. The first item on each line is a word, the second\\na part-of-speech (POS) tag, the third a syntactic chunk tag and the fourth the named entity tag. The chunk tags\\nand the named entity tags have the format I-TYPE which means that the word is inside a phrase of type TYPE. Only\\nif two phrases of the same type immediately follow each other, the first word of the second phrase will have tag\\nB-TYPE to show that it starts a new phrase. A word with tag O is not part of a phrase. Note the dataset uses IOB2\\ntagging scheme, whereas the original dataset uses IOB1.\\n\\nFor more details see https://www.clips.uantwerpen.be/conll2003/ner/ and https://www.aclweb.org/anthology/W03-0419\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-uncased\")"],"metadata":{"id":"3d6NuewJL-kA","executionInfo":{"status":"ok","timestamp":1693313822113,"user_tz":-330,"elapsed":1271,"user":{"displayName":"Atanu Kundu","userId":"00561738222071394876"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["# Tests\n","\n","conll2003['train'][0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kqxD9FT-MIXO","executionInfo":{"status":"ok","timestamp":1693313826222,"user_tz":-330,"elapsed":1017,"user":{"displayName":"Atanu Kundu","userId":"00561738222071394876"}},"outputId":"6ea1a9a8-73f8-4e75-a73e-c62e0372ff31"},"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'id': '0',\n"," 'tokens': ['EU',\n","  'rejects',\n","  'German',\n","  'call',\n","  'to',\n","  'boycott',\n","  'British',\n","  'lamb',\n","  '.'],\n"," 'pos_tags': [22, 42, 16, 21, 35, 37, 16, 21, 7],\n"," 'chunk_tags': [11, 21, 11, 12, 21, 22, 11, 12, 0],\n"," 'ner_tags': [3, 0, 7, 0, 0, 0, 7, 0, 0]}"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["example_text = conll2003['train'][0]\n","tokenized_input = tokenizer(example_text[\"tokens\"], is_split_into_words=True)\n","tokens = tokenizer.convert_ids_to_tokens(tokenized_input[\"input_ids\"])"],"metadata":{"id":"n4USltk6MITu","executionInfo":{"status":"ok","timestamp":1693313829503,"user_tz":-330,"elapsed":7,"user":{"displayName":"Atanu Kundu","userId":"00561738222071394876"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["word_ids = tokenized_input.word_ids()\n","\n","print(word_ids)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cdSKtGfqMIRP","executionInfo":{"status":"ok","timestamp":1693313831699,"user_tz":-330,"elapsed":16,"user":{"displayName":"Atanu Kundu","userId":"00561738222071394876"}},"outputId":"b38f226c-b3ce-4b4b-d97c-37140197b78d"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["[None, 0, 1, 2, 3, 4, 5, 6, 7, 8, None]\n"]}]},{"cell_type":"code","source":["tokenized_input"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZpvmnmFXMdh1","executionInfo":{"status":"ok","timestamp":1693313835731,"user_tz":-330,"elapsed":16,"user":{"displayName":"Atanu Kundu","userId":"00561738222071394876"}},"outputId":"c479bf0b-2221-4dde-b2ba-a950a39ef85f"},"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'input_ids': [101, 7327, 19164, 2446, 2655, 2000, 17757, 2329, 12559, 1012, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["tokens = tokenizer.convert_ids_to_tokens(tokenized_input[\"input_ids\"])\n","tokens"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"12iNB_uaMdfR","executionInfo":{"status":"ok","timestamp":1693313840187,"user_tz":-330,"elapsed":11,"user":{"displayName":"Atanu Kundu","userId":"00561738222071394876"}},"outputId":"8265816b-c166-47f4-8358-61abed4696f3"},"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['[CLS]',\n"," 'eu',\n"," 'rejects',\n"," 'german',\n"," 'call',\n"," 'to',\n"," 'boycott',\n"," 'british',\n"," 'lamb',\n"," '.',\n"," '[SEP]']"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["len(tokens)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FH04u3tIOWH_","executionInfo":{"status":"ok","timestamp":1693313843606,"user_tz":-330,"elapsed":19,"user":{"displayName":"Atanu Kundu","userId":"00561738222071394876"}},"outputId":"e1c439da-d64c-4956-b10b-070c3bb887df"},"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["11"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["len(conll2003['train'][0]['ner_tags'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PalC9nKxOffR","executionInfo":{"status":"ok","timestamp":1693313846033,"user_tz":-330,"elapsed":11,"user":{"displayName":"Atanu Kundu","userId":"00561738222071394876"}},"outputId":"0711575b-6963-4780-856e-97667ef23f9e"},"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["9"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["conll2003['train'][0]['ner_tags']"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0Cr2DpqIOxGi","executionInfo":{"status":"ok","timestamp":1693313849962,"user_tz":-330,"elapsed":14,"user":{"displayName":"Atanu Kundu","userId":"00561738222071394876"}},"outputId":"f917681f-28b1-4083-fb88-c1ce62f913ec"},"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[3, 0, 7, 0, 0, 0, 7, 0, 0]"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","source":["def tokenize_and_align_labels(examples, label_all_tokens=True):\n","    tokenized_inputs = tokenizer(examples[\"tokens\"], truncation=True, is_split_into_words=True)\n","    labels = []\n","    for i, label in enumerate(examples[\"ner_tags\"]):\n","        word_ids = tokenized_inputs.word_ids(batch_index=i)\n","        # word_ids() => Return a list mapping the tokens\n","        # to their actual word in the initial sentence.\n","        # It Returns a list indicating the word corresponding to each token.\n","        previous_word_idx = None\n","        label_ids = []\n","        # Special tokens like `` and `<\\s>` are originally mapped to None\n","        # We need to set the label to -100 so they are automatically ignored in the loss function.\n","        for word_idx in word_ids:\n","            if word_idx is None:\n","                # set –100 as the label for these special tokens\n","                label_ids.append(-100)\n","            # For the other tokens in a word, we set the label to either the current label or -100, depending on\n","            # the label_all_tokens flag.\n","            elif word_idx != previous_word_idx:\n","                # if current word_idx is != prev then its the most regular case\n","                # and add the corresponding token\n","                label_ids.append(label[word_idx])\n","            else:\n","                # to take care of sub-words which have the same word_idx\n","                # set -100 as well for them, but only if label_all_tokens == False\n","                label_ids.append(label[word_idx] if label_all_tokens else -100)\n","                # mask the subword representations after the first subword\n","\n","            previous_word_idx = word_idx\n","        labels.append(label_ids)\n","    tokenized_inputs[\"labels\"] = labels\n","    return tokenized_inputs"],"metadata":{"id":"rHN4WYRkO7c_","executionInfo":{"status":"ok","timestamp":1693313852453,"user_tz":-330,"elapsed":7,"user":{"displayName":"Atanu Kundu","userId":"00561738222071394876"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["conll2003['train'][4:5]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gzeGTxfJPYjr","executionInfo":{"status":"ok","timestamp":1693313855242,"user_tz":-330,"elapsed":18,"user":{"displayName":"Atanu Kundu","userId":"00561738222071394876"}},"outputId":"25de9770-187a-4931-cc45-9ca773a0b205"},"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'id': ['4'],\n"," 'tokens': [['Germany',\n","   \"'s\",\n","   'representative',\n","   'to',\n","   'the',\n","   'European',\n","   'Union',\n","   \"'s\",\n","   'veterinary',\n","   'committee',\n","   'Werner',\n","   'Zwingmann',\n","   'said',\n","   'on',\n","   'Wednesday',\n","   'consumers',\n","   'should',\n","   'buy',\n","   'sheepmeat',\n","   'from',\n","   'countries',\n","   'other',\n","   'than',\n","   'Britain',\n","   'until',\n","   'the',\n","   'scientific',\n","   'advice',\n","   'was',\n","   'clearer',\n","   '.']],\n"," 'pos_tags': [[22,\n","   27,\n","   21,\n","   35,\n","   12,\n","   22,\n","   22,\n","   27,\n","   16,\n","   21,\n","   22,\n","   22,\n","   38,\n","   15,\n","   22,\n","   24,\n","   20,\n","   37,\n","   21,\n","   15,\n","   24,\n","   16,\n","   15,\n","   22,\n","   15,\n","   12,\n","   16,\n","   21,\n","   38,\n","   17,\n","   7]],\n"," 'chunk_tags': [[11,\n","   11,\n","   12,\n","   13,\n","   11,\n","   12,\n","   12,\n","   11,\n","   12,\n","   12,\n","   12,\n","   12,\n","   21,\n","   13,\n","   11,\n","   12,\n","   21,\n","   22,\n","   11,\n","   13,\n","   11,\n","   1,\n","   13,\n","   11,\n","   17,\n","   11,\n","   12,\n","   12,\n","   21,\n","   1,\n","   0]],\n"," 'ner_tags': [[5,\n","   0,\n","   0,\n","   0,\n","   0,\n","   3,\n","   4,\n","   0,\n","   0,\n","   0,\n","   1,\n","   2,\n","   0,\n","   0,\n","   0,\n","   0,\n","   0,\n","   0,\n","   0,\n","   0,\n","   0,\n","   0,\n","   0,\n","   5,\n","   0,\n","   0,\n","   0,\n","   0,\n","   0,\n","   0,\n","   0]]}"]},"metadata":{},"execution_count":19}]},{"cell_type":"code","source":["q = tokenize_and_align_labels(conll2003['train'][4:5])\n","print(q)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Hkofw5lCPYgm","executionInfo":{"status":"ok","timestamp":1693313858016,"user_tz":-330,"elapsed":13,"user":{"displayName":"Atanu Kundu","userId":"00561738222071394876"}},"outputId":"05848e3d-e71e-4d6f-feff-8ce46cbac3b8"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["{'input_ids': [[101, 2762, 1005, 1055, 4387, 2000, 1996, 2647, 2586, 1005, 1055, 15651, 2837, 14121, 1062, 9328, 5804, 2056, 2006, 9317, 10390, 2323, 4965, 8351, 4168, 4017, 2013, 3032, 2060, 2084, 3725, 2127, 1996, 4045, 6040, 2001, 24509, 1012, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': [[-100, 5, 0, 0, 0, 0, 0, 3, 4, 0, 0, 0, 0, 1, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, -100]]}\n"]}]},{"cell_type":"code","source":["for token, label in zip(tokenizer.convert_ids_to_tokens(q[\"input_ids\"][0]),q[\"labels\"][0]):\n","    print(f\"{token:_<40} {label}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7m3o2nMrPYd3","executionInfo":{"status":"ok","timestamp":1693313862100,"user_tz":-330,"elapsed":13,"user":{"displayName":"Atanu Kundu","userId":"00561738222071394876"}},"outputId":"17fd89b7-12be-4d20-fb46-876fed003a6b"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["[CLS]___________________________________ -100\n","germany_________________________________ 5\n","'_______________________________________ 0\n","s_______________________________________ 0\n","representative__________________________ 0\n","to______________________________________ 0\n","the_____________________________________ 0\n","european________________________________ 3\n","union___________________________________ 4\n","'_______________________________________ 0\n","s_______________________________________ 0\n","veterinary______________________________ 0\n","committee_______________________________ 0\n","werner__________________________________ 1\n","z_______________________________________ 2\n","##wing__________________________________ 2\n","##mann__________________________________ 2\n","said____________________________________ 0\n","on______________________________________ 0\n","wednesday_______________________________ 0\n","consumers_______________________________ 0\n","should__________________________________ 0\n","buy_____________________________________ 0\n","sheep___________________________________ 0\n","##me____________________________________ 0\n","##at____________________________________ 0\n","from____________________________________ 0\n","countries_______________________________ 0\n","other___________________________________ 0\n","than____________________________________ 0\n","britain_________________________________ 5\n","until___________________________________ 0\n","the_____________________________________ 0\n","scientific______________________________ 0\n","advice__________________________________ 0\n","was_____________________________________ 0\n","clearer_________________________________ 0\n","._______________________________________ 0\n","[SEP]___________________________________ -100\n"]}]},{"cell_type":"code","source":["## Applying on entire data\n","tokenized_datasets = conll2003.map(tokenize_and_align_labels, batched=True)"],"metadata":{"id":"7XNbR85MPYbZ","executionInfo":{"status":"ok","timestamp":1693313864188,"user_tz":-330,"elapsed":12,"user":{"displayName":"Atanu Kundu","userId":"00561738222071394876"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["tokenized_datasets['train'][0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Jrys7U15P4X4","executionInfo":{"status":"ok","timestamp":1693313867597,"user_tz":-330,"elapsed":13,"user":{"displayName":"Atanu Kundu","userId":"00561738222071394876"}},"outputId":"3aeb8c45-7adf-476d-9d77-c5fb7b7d1a0a"},"execution_count":23,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'id': '0',\n"," 'tokens': ['EU',\n","  'rejects',\n","  'German',\n","  'call',\n","  'to',\n","  'boycott',\n","  'British',\n","  'lamb',\n","  '.'],\n"," 'pos_tags': [22, 42, 16, 21, 35, 37, 16, 21, 7],\n"," 'chunk_tags': [11, 21, 11, 12, 21, 22, 11, 12, 0],\n"," 'ner_tags': [3, 0, 7, 0, 0, 0, 7, 0, 0],\n"," 'input_ids': [101,\n","  7327,\n","  19164,\n","  2446,\n","  2655,\n","  2000,\n","  17757,\n","  2329,\n","  12559,\n","  1012,\n","  102],\n"," 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n"," 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n"," 'labels': [-100, 3, 0, 7, 0, 0, 0, 7, 0, 0, -100]}"]},"metadata":{},"execution_count":23}]},{"cell_type":"code","source":["# Defining model\n","\n","model = AutoModelForTokenClassification.from_pretrained(\"bert-base-uncased\", num_labels=9)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Tte1hRxuP4Vg","executionInfo":{"status":"ok","timestamp":1693313874539,"user_tz":-330,"elapsed":3397,"user":{"displayName":"Atanu Kundu","userId":"00561738222071394876"}},"outputId":"12eca8c8-57be-4a62-fe86-de20a61bb85e"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}]},{"cell_type":"code","source":["#Define training args\n","from transformers import TrainingArguments, Trainer\n","\n","\n","args = TrainingArguments(\n","\"test-ner\",\n","evaluation_strategy = \"epoch\",\n","learning_rate=2e-5,\n","per_device_train_batch_size=16,\n","per_device_eval_batch_size=16,\n","num_train_epochs=1,\n","weight_decay=0.01,\n",")"],"metadata":{"id":"fBvR1_ZsQQ2D","executionInfo":{"status":"ok","timestamp":1693313878880,"user_tz":-330,"elapsed":1052,"user":{"displayName":"Atanu Kundu","userId":"00561738222071394876"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["data_collator = DataCollatorForTokenClassification(tokenizer)"],"metadata":{"id":"7AJxTngRQQzz","executionInfo":{"status":"ok","timestamp":1693313898817,"user_tz":-330,"elapsed":1692,"user":{"displayName":"Atanu Kundu","userId":"00561738222071394876"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["metric = datasets.load_metric(\"seqeval\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":104,"referenced_widgets":["2b5a92096c9047bb80e6194c2f53314d","22e1ce10beef43b9a4a00bdbff7f4e97","cdcb1f50b5ca4fbba9ceace045f95ce2","0321db72097946e192e48c5c7c42fb4b","a9a988fdeb614c9f8a1f2efead4ec81d","a47b308db3df4ab19283732136401495","76a7611748414f009b22e01ec3a2f2f0","03beaac1b7e5423da1ddd1d231a707b0","c854188f46e242f0a2cf06ff04cd5793","53d7b36db74144f687e51966e57cf97d","fae165e1aa034aaf9189139af5bd62de"]},"id":"ndFqka5NQQxU","executionInfo":{"status":"ok","timestamp":1693313909145,"user_tz":-330,"elapsed":3657,"user":{"displayName":"Atanu Kundu","userId":"00561738222071394876"}},"outputId":"06a3d786-61ec-48ab-ff79-f71192b4d67a"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-27-b144b02b338d>:1: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n","  metric = datasets.load_metric(\"seqeval\")\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading builder script:   0%|          | 0.00/2.47k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2b5a92096c9047bb80e6194c2f53314d"}},"metadata":{}}]},{"cell_type":"code","source":["example = conll2003['train'][0]"],"metadata":{"id":"foBvDPseROeo","executionInfo":{"status":"ok","timestamp":1693313939566,"user_tz":-330,"elapsed":11,"user":{"displayName":"Atanu Kundu","userId":"00561738222071394876"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["label_list = conll2003[\"train\"].features[\"ner_tags\"].feature.names\n","\n","label_list"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i7MMraTNROcB","executionInfo":{"status":"ok","timestamp":1693313961922,"user_tz":-330,"elapsed":2572,"user":{"displayName":"Atanu Kundu","userId":"00561738222071394876"}},"outputId":"8f1ce8e8-25b6-40f2-90bf-f3c34b8bf684"},"execution_count":29,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC']"]},"metadata":{},"execution_count":29}]},{"cell_type":"code","source":["for i in example[\"ner_tags\"]:\n","  print(i)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CaGzq15eRTYA","executionInfo":{"status":"ok","timestamp":1693313972752,"user_tz":-330,"elapsed":43,"user":{"displayName":"Atanu Kundu","userId":"00561738222071394876"}},"outputId":"8e34546e-f3b4-4754-f839-68da5bbf4b49"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["3\n","0\n","7\n","0\n","0\n","0\n","7\n","0\n","0\n"]}]},{"cell_type":"code","source":["labels = [label_list[i] for i in example[\"ner_tags\"]]\n","labels"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZvlWKsZ9RVln","executionInfo":{"status":"ok","timestamp":1693313993713,"user_tz":-330,"elapsed":3332,"user":{"displayName":"Atanu Kundu","userId":"00561738222071394876"}},"outputId":"2fb6ca06-6572-4bb6-f755-7cb73042f989"},"execution_count":31,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['B-ORG', 'O', 'B-MISC', 'O', 'O', 'O', 'B-MISC', 'O', 'O']"]},"metadata":{},"execution_count":31}]},{"cell_type":"code","source":["metric.compute(predictions=[labels], references=[labels])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jbZ36xmcRX4Y","executionInfo":{"status":"ok","timestamp":1693314028786,"user_tz":-330,"elapsed":1056,"user":{"displayName":"Atanu Kundu","userId":"00561738222071394876"}},"outputId":"d401fb4f-beb0-4e60-9d40-cabe01e607b7"},"execution_count":32,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'MISC': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 2},\n"," 'ORG': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 1},\n"," 'overall_precision': 1.0,\n"," 'overall_recall': 1.0,\n"," 'overall_f1': 1.0,\n"," 'overall_accuracy': 1.0}"]},"metadata":{},"execution_count":32}]},{"cell_type":"code","source":["def compute_metrics(eval_preds):\n","    pred_logits, labels = eval_preds\n","\n","    pred_logits = np.argmax(pred_logits, axis=2)\n","    # the logits and the probabilities are in the same order,\n","    # so we don’t need to apply the softmax\n","\n","    # We remove all the values where the label is -100\n","    predictions = [\n","        [label_list[eval_preds] for (eval_preds, l) in zip(prediction, label) if l != -100]\n","        for prediction, label in zip(pred_logits, labels)\n","    ]\n","\n","    true_labels = [\n","      [label_list[l] for (eval_preds, l) in zip(prediction, label) if l != -100]\n","       for prediction, label in zip(pred_logits, labels)\n","   ]\n","    results = metric.compute(predictions=predictions, references=true_labels)\n","\n","    return {\n","          \"precision\": results[\"overall_precision\"],\n","          \"recall\": results[\"overall_recall\"],\n","          \"f1\": results[\"overall_f1\"],\n","          \"accuracy\": results[\"overall_accuracy\"],\n","  }"],"metadata":{"id":"Y_b7QXoDRsQk","executionInfo":{"status":"ok","timestamp":1693314172923,"user_tz":-330,"elapsed":1432,"user":{"displayName":"Atanu Kundu","userId":"00561738222071394876"}}},"execution_count":33,"outputs":[]},{"cell_type":"code","source":["tokenized_datasets"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UO-_WifyRsNE","executionInfo":{"status":"ok","timestamp":1693314193926,"user_tz":-330,"elapsed":979,"user":{"displayName":"Atanu Kundu","userId":"00561738222071394876"}},"outputId":"f58f87c0-803c-406b-e86f-8e326b1cb9e5"},"execution_count":34,"outputs":[{"output_type":"execute_result","data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n","        num_rows: 14041\n","    })\n","    validation: Dataset({\n","        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n","        num_rows: 3250\n","    })\n","    test: Dataset({\n","        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n","        num_rows: 3453\n","    })\n","})"]},"metadata":{},"execution_count":34}]},{"cell_type":"code","source":["trainer = Trainer(\n","   model,\n","   args,\n","   train_dataset=tokenized_datasets[\"train\"],\n","   eval_dataset=tokenized_datasets[\"validation\"],\n","   data_collator=data_collator,\n","   tokenizer=tokenizer,\n","   compute_metrics=compute_metrics\n",")"],"metadata":{"id":"cU5UN_R8RsKq","executionInfo":{"status":"ok","timestamp":1693314254833,"user_tz":-330,"elapsed":6578,"user":{"displayName":"Atanu Kundu","userId":"00561738222071394876"}}},"execution_count":35,"outputs":[]},{"cell_type":"code","source":["trainer.train()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":196},"id":"eJ74jCCFSQch","executionInfo":{"status":"ok","timestamp":1693314456338,"user_tz":-330,"elapsed":169342,"user":{"displayName":"Atanu Kundu","userId":"00561738222071394876"}},"outputId":"a7005b56-7e5f-4240-fe35-c0024b0985b1"},"execution_count":36,"outputs":[{"output_type":"stream","name":"stderr","text":["You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='878' max='878' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [878/878 02:44, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","      <th>Accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.225400</td>\n","      <td>0.070523</td>\n","      <td>0.902495</td>\n","      <td>0.922586</td>\n","      <td>0.912430</td>\n","      <td>0.980714</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=878, training_loss=0.16505891369795744, metrics={'train_runtime': 167.5972, 'train_samples_per_second': 83.778, 'train_steps_per_second': 5.239, 'total_flos': 342221911376202.0, 'train_loss': 0.16505891369795744, 'epoch': 1.0})"]},"metadata":{},"execution_count":36}]},{"cell_type":"code","source":["## Save model\n","model.save_pretrained(\"ner_model\")"],"metadata":{"id":"GNgg5MAcSm28","executionInfo":{"status":"ok","timestamp":1693314531978,"user_tz":-330,"elapsed":8154,"user":{"displayName":"Atanu Kundu","userId":"00561738222071394876"}}},"execution_count":37,"outputs":[]},{"cell_type":"code","source":["## Save tokenizer\n","tokenizer.save_pretrained(\"tokenizer\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ixIR7V8iSmzm","executionInfo":{"status":"ok","timestamp":1693314563557,"user_tz":-330,"elapsed":1016,"user":{"displayName":"Atanu Kundu","userId":"00561738222071394876"}},"outputId":"c2b2e33c-d7ef-48ad-a3db-d1eb1a540d0a"},"execution_count":38,"outputs":[{"output_type":"execute_result","data":{"text/plain":["('tokenizer/tokenizer_config.json',\n"," 'tokenizer/special_tokens_map.json',\n"," 'tokenizer/vocab.txt',\n"," 'tokenizer/added_tokens.json',\n"," 'tokenizer/tokenizer.json')"]},"metadata":{},"execution_count":38}]},{"cell_type":"code","source":["id2label = {\n","    str(i): label for i,label in enumerate(label_list)\n","}\n","label2id = {\n","    label: str(i) for i,label in enumerate(label_list)\n","}"],"metadata":{"id":"RTRJEHi7S7oq","executionInfo":{"status":"ok","timestamp":1693314662166,"user_tz":-330,"elapsed":667,"user":{"displayName":"Atanu Kundu","userId":"00561738222071394876"}}},"execution_count":40,"outputs":[]},{"cell_type":"code","source":["id2label"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"74IVxb0jS-ux","executionInfo":{"status":"ok","timestamp":1693314665736,"user_tz":-330,"elapsed":17,"user":{"displayName":"Atanu Kundu","userId":"00561738222071394876"}},"outputId":"1a2b62a1-485a-4c54-8134-66bd6483ca50"},"execution_count":41,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'0': 'O',\n"," '1': 'B-PER',\n"," '2': 'I-PER',\n"," '3': 'B-ORG',\n"," '4': 'I-ORG',\n"," '5': 'B-LOC',\n"," '6': 'I-LOC',\n"," '7': 'B-MISC',\n"," '8': 'I-MISC'}"]},"metadata":{},"execution_count":41}]},{"cell_type":"code","source":["label2id"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r2Uc0uvvTAsI","executionInfo":{"status":"ok","timestamp":1693314693124,"user_tz":-330,"elapsed":119,"user":{"displayName":"Atanu Kundu","userId":"00561738222071394876"}},"outputId":"b10d44f9-2b92-4eb3-d8c4-5d167f614a39"},"execution_count":42,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'O': '0',\n"," 'B-PER': '1',\n"," 'I-PER': '2',\n"," 'B-ORG': '3',\n"," 'I-ORG': '4',\n"," 'B-LOC': '5',\n"," 'I-LOC': '6',\n"," 'B-MISC': '7',\n"," 'I-MISC': '8'}"]},"metadata":{},"execution_count":42}]},{"cell_type":"code","source":["import json"],"metadata":{"id":"OtSttZoyTV4Y","executionInfo":{"status":"ok","timestamp":1693314787507,"user_tz":-330,"elapsed":1269,"user":{"displayName":"Atanu Kundu","userId":"00561738222071394876"}}},"execution_count":43,"outputs":[]},{"cell_type":"code","source":["config = json.load(open(\"ner_model/config.json\"))\n","config[\"id2label\"] = id2label\n","config[\"label2id\"] = label2id\n","json.dump(config, open(\"ner_model/config.json\",\"w\"))"],"metadata":{"id":"y0mdpZWhTF2A","executionInfo":{"status":"ok","timestamp":1693314803115,"user_tz":-330,"elapsed":710,"user":{"displayName":"Atanu Kundu","userId":"00561738222071394876"}}},"execution_count":44,"outputs":[]},{"cell_type":"code","source":["model_fine_tuned = AutoModelForTokenClassification.from_pretrained(\"ner_model\")"],"metadata":{"id":"OuGkejVQTYWo","executionInfo":{"status":"ok","timestamp":1693314896066,"user_tz":-330,"elapsed":3780,"user":{"displayName":"Atanu Kundu","userId":"00561738222071394876"}}},"execution_count":45,"outputs":[]},{"cell_type":"code","source":["from transformers import pipeline"],"metadata":{"id":"QOyFNXd1Tlsr","executionInfo":{"status":"ok","timestamp":1693314907937,"user_tz":-330,"elapsed":824,"user":{"displayName":"Atanu Kundu","userId":"00561738222071394876"}}},"execution_count":46,"outputs":[]},{"cell_type":"code","source":["nlp = pipeline(\"ner\", model=model_fine_tuned, tokenizer=tokenizer)\n"],"metadata":{"id":"FGfZTPQfTpRO","executionInfo":{"status":"ok","timestamp":1693314912088,"user_tz":-330,"elapsed":15,"user":{"displayName":"Atanu Kundu","userId":"00561738222071394876"}}},"execution_count":47,"outputs":[]},{"cell_type":"code","source":["# example = \"Bill Gates is the Founder of Microsoft\"\n","example = \"Atanu Kundu is the Founder of Microsoft\"\n","ner_results = nlp(example)\n","\n","print(ner_results)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_WYzl1DlTpOI","executionInfo":{"status":"ok","timestamp":1693315272347,"user_tz":-330,"elapsed":665,"user":{"displayName":"Atanu Kundu","userId":"00561738222071394876"}},"outputId":"83141b4a-bf9c-4fc4-8b17-040be2a26ea9"},"execution_count":49,"outputs":[{"output_type":"stream","name":"stdout","text":["[{'entity': 'B-PER', 'score': 0.9890007, 'index': 1, 'word': 'ata', 'start': 0, 'end': 3}, {'entity': 'B-PER', 'score': 0.9929657, 'index': 2, 'word': '##nu', 'start': 3, 'end': 5}, {'entity': 'I-PER', 'score': 0.99595094, 'index': 3, 'word': 'kun', 'start': 6, 'end': 9}, {'entity': 'I-PER', 'score': 0.99496526, 'index': 4, 'word': '##du', 'start': 9, 'end': 11}, {'entity': 'B-ORG', 'score': 0.78547114, 'index': 9, 'word': 'microsoft', 'start': 30, 'end': 39}]\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"cmIrZXaVTpI4"},"execution_count":null,"outputs":[]}]}